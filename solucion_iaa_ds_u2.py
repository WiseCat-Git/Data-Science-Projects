# -*- coding: utf-8 -*-
"""Solucion_IAA_DS_u2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1II1iCxpgNAUFLzqtl-B1DaxbECilqOuW

# **Enunciado**

En esta unidad hemos aprendido a realizar un An√°lisis Exploratorio de Datos con Python. En esta activad vamos a poner en pr√°ctica lo aprendido con un conjunto de datos real. Disponemos de un dataset con la informaci√≥n de admisiones a hospitales de enfermos de diabetes.

El objetivo final del proyecto es, estudiando el historial cl√≠nico de cada paciente, saber cu√°les de ellos tienen una alta probabilidad de ser readmitidos en los pr√≥ximos 30 d√≠as por problemas de diabetes. En el siguiente enlace puedes encontrar una descripci√≥n de todas las columnas:

https://fairlearn.org/main/user_guide/datasets/diabetes_hospital_data.html

La variable objetivo de nuestro estudio se llama readmit_30_days y es una variable binaria, 1 si el paciente fue readmitido en los siguientes 30 d√≠as y 0 en caso contrario.  

Ten en cuenta a la hora de estudiar las variables que las columnas readmitted y readmit_binary contienen esta misma informaci√≥n tambi√©n pero no podr√≠amos utilizarlas a la hora de predecir la otra porque realmente no se conocen hasta que un paciente es readmitido, que es el objetivo de nuestra predicci√≥n.

En modelos predictivos siempre hay que tener mucho cuidado con esto.

El esto de variables pueden ser consideradas variables independientes, algunas ser√°n de tipo num√©rico y muchas de ellas de tipo categ√≥rico o binarias.

En esta actividad vamos a hacer un an√°lisis exploratorio de datos tanto Univariante como Bivariante para entender mejor qu√© tratamientos tenemos que dar a cada variable y cu√°les pueden ser relevantes a la hora de predecir si un paciente ser√° readmitido en los pr√≥ximos 30 d√≠as.

# **An√°lisis Univariante**

Identificaci√≥n y Tratamiento de Nulos Cuenta cuantos valores nulos hay de cada variable, qu√© % representan y toma decisiones sobre c√≥mo tratarlos.

Despu√©s de este paso no deber√≠a quedar ning√∫n valor nulo.

# **An√°lisis de Variables Categ√≥ricas**

Ya que algunas veces se conviertes variables categ√≥ricas a num√©ricas vamos a empezar nuestro an√°lisis por estas, incluyendo como categ√≥ricas las booleanas (True/False).

Haz un estudio de cada una de ellas de manera individualizada como vimos en la teor√≠a.  

Como a√∫n no vamos a trabajar con modelos de Machine Learning no es necesario la conversi√≥n a dummies final pero si ves alguna variable que √∫nicamente toma dos valores convi√©rtela a booleana, ser√° m√°s c√≥modo trabajar con ella m√°s adelante.

Las preguntas que debemos ser capaces de responder son del tipo:

1. ¬øhay columnas con valores constantes o casi constantes?
2. ¬øSe debe reducir el n√∫mero de categor√≠as de alguna variable?
3. ¬øtienen sentido los datos observados?

Adem√°s, aunque es una tareas m√°s de tratamiento de datos, elimina todos los espacios de los valores de las categ√≥ricas que suelen dar problemas a veces y reempl√°zalos por '_'.

# **An√°lisis de Variables Num√©ricas**

An√°lisis Multivariante Estudia ahora cada una de las variables num√©ricas, observa las distribuciones y discute la presencia de outliers y la forma de tratarlos en cada caso.

Deber√≠as como m√≠nimo mostrar los boxplots y los histogramas de cada una de las variables para conocer su distribuci√≥n.

Una vez completado el an√°lisis univariante es hora de hacer el bivariante

1. ¬øc√≥mo se comportan las variables entre ellas? Nos importa especialmente la relaci√≥n de cada variable con nuestro objetivo readmit_30_days.

# **Num√©rica vs Num√©rica**

Realiza primero un estudio de las correlaciones de todas las variables num√©ricas entre ellas

1. ¬øhay alguna altamente correlada que podr√≠amos descartar? Si es as√≠ muestra un scatter plot tambi√©n de ellas para confirmar las sospechas.

# **Num√©rica vs Categ√≥rica**

En esta fase la idea principal es comparar cada una de las variables num√©ricas contra la variable objetivo, ¬øtienen todas algo de relaci√≥n con la probabilidad de un paciente ser readmitido a los 30 d√≠as? ¬øpodemos ya descartar alguna?

# **Categ√≥rica vs Categ√≥rica**

Al igual que con las num√©ricas, observa el comportamiento de cada una de estas variables categ√≥ricas con respecto a la variable objetivo. Emplea los test de chicuadrado

# **C√≥digo**

**Instalamos las librerias necesarias**
"""

# Instalar librer√≠as necesarias
!pip install fairlearn pandas numpy matplotlib seaborn scipy

# Importar librer√≠as
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from fairlearn.datasets import fetch_diabetes_hospital
from scipy.stats import chi2_contingency

# Configuraci√≥n de visualizaci√≥n
plt.style.use('ggplot')
pd.set_option('display.max_columns', None)

# Cargar el dataset desde Fairlearn
dataset = fetch_diabetes_hospital(as_frame=True)
data = dataset['data']  # Asegurar que 'data' est√° correctamente asignado

# Mostrar las primeras filas para confirmar que los datos se cargaron correctamente
print("Vista previa de los datos:")
display(data.head())

# Mostrar informaci√≥n general del dataset
print("\nInformaci√≥n del dataset:")
data.info()

# Verificar valores nulos
print("\nValores nulos por columna:")
print(data.isnull().sum())

"""# **Manejo de Valores Nulos**"""

# Identificar valores nulos
missing_values = data.isnull().sum()
missing_percentage = (missing_values / len(data)) * 100
missing_df = pd.DataFrame({'Valores Nulos': missing_values, 'Porcentaje': missing_percentage})
missing_df = missing_df[missing_df['Valores Nulos'] > 0].sort_values(by='Porcentaje', ascending=False)

# Si hay valores nulos, los mostramos
if not missing_df.empty:
    print("\nVariables con valores nulos:")
    display(missing_df)

    # Tratamiento de valores nulos
    for col in data.columns:
        if data[col].dtype == 'object' or data[col].dtype.name == 'category':
            # Reemplazar valores nulos en columnas categ√≥ricas con "Desconocido"
            data[col] = data[col].fillna('Desconocido')
        elif np.issubdtype(data[col].dtype, np.number):
            # Reemplazar valores nulos en columnas num√©ricas con la mediana
            data[col] = data[col].fillna(data[col].median())

    # Verificar que no haya nulos despu√©s del tratamiento
    print("\nValores nulos despu√©s del tratamiento:", data.isnull().sum().sum())  # Debe ser 0
else:
    print("\n‚úÖ No hay valores nulos en el dataset.")

"""# **An√°lisis Univariante**

**A) Variables Categ√≥ricas**
"""

# Reemplazar espacios en valores categ√≥ricos para evitar problemas en modelos
for col in data.select_dtypes(include=['object']).columns:
    data.loc[:, col] = data[col].str.replace(' ', '_')

# Resumen de variables categ√≥ricas
print("\nüîç Resumen de variables categ√≥ricas:")
for col in data.select_dtypes(include=['object']).columns:
    print(f"üìå {col}: {data[col].nunique()} categor√≠as")
    print(data[col].value_counts(normalize=True) * 100)
    print("\n")

# Convertir variables binarias a 0 y 1 para facilitar an√°lisis
binary_cols = ['diabetesMed', 'medicare', 'medicaid', 'had_emergency', 'had_inpatient_days', 'had_outpatient_days', 'readmit_binary']

for col in binary_cols:
    if data[col].dtype == 'object':  # Asegurar que es tipo 'object' antes de reemplazar
        data.loc[:, col] = data[col].replace({'No': 0, 'Yes': 1}).astype(int)

# Verificar que las variables binarias fueron correctamente convertidas
print("\n‚úÖ Verificaci√≥n de variables binarias:")
print(data[binary_cols].head())

"""**B) Variables Num√©ricas**"""

# Estad√≠sticas de variables num√©ricas
print("\nResumen de variables num√©ricas:")
display(data.describe())

# Boxplot para detectar outliers
plt.figure(figsize=(12, 6))
sns.boxplot(data=data.select_dtypes(include=[np.number]))
plt.title("Boxplot de Variables Num√©ricas")
plt.xticks(rotation=45)
plt.show()

# Histogramas de variables num√©ricas
data.select_dtypes(include=[np.number]).hist(figsize=(12, 10), bins=30, edgecolor='black')
plt.suptitle("Histogramas de Variables Num√©ricas", fontsize=16)
plt.show()

"""# **An√°lisis Bivariante**

**A) Correlaci√≥n entre Variables Num√©ricas**
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Seleccionamos solo las columnas num√©ricas para evitar errores en la correlaci√≥n
numeric_data = data.select_dtypes(include=['int64', 'float64'])

# Matriz de correlaci√≥n corregida
plt.figure(figsize=(12, 6))
sns.heatmap(numeric_data.corr(), annot=True, fmt=".2f", cmap='coolwarm', linewidths=0.5)
plt.title("Matriz de Correlaci√≥n entre Variables Num√©ricas")
plt.show()

# Identificar pares de variables altamente correlacionadas (correlaci√≥n > 0.7)
correlated_features = set()
correlation_matrix = numeric_data.corr()

for i in range(len(correlation_matrix.columns)):
    for j in range(i):
        if abs(correlation_matrix.iloc[i, j]) > 0.7:
            colname = correlation_matrix.columns[i]
            correlated_features.add(colname)

print("\nVariables altamente correlacionadas que podr√≠amos descartar:")
print(correlated_features)

"""No hay variables con correlaci√≥n > 0.7, por lo que no es necesario eliminar ninguna por multicolinealidad.
Sin embargo, si buscamos reducir la dimensionalidad, podr√≠amos explorar m√©todos como PCA (An√°lisis de Componentes Principales) o realizar pruebas con modelos para ver qu√© variables realmente aportan al rendimiento.

**B) Relaci√≥n entre Variables Num√©ricas y readmit_30_days**
"""

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Identificamos columnas num√©ricas excluyendo las binarias (0 y 1)
numeric_cols = [col for col in data.select_dtypes(include=[np.number]).columns if data[col].nunique() > 2]

# Boxplot de variables num√©ricas contra la variable objetivo
for col in numeric_cols:
    plt.figure(figsize=(8, 4))
    sns.boxplot(x=data['readmit_binary'].astype(str), y=data[col])
    plt.title(f"Distribuci√≥n de {col} por Readmisi√≥n")
    plt.xlabel("Readmitido en 30 d√≠as (0 = No, 1 = S√≠)")
    plt.ylabel(col)
    plt.show()

"""**C) Relaci√≥n entre Variables Categ√≥ricas y readmit_30_days**"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import chi2_contingency

# Test de chi-cuadrado para variables categ√≥ricas
print("\n Test de Chi-Cuadrado entre variables categ√≥ricas y la readmisi√≥n:")
categorical_cols = data.select_dtypes(include=['object', 'category']).columns

for col in categorical_cols:
    contingency_table = pd.crosstab(data[col], data['readmit_binary'], dropna=False)
    chi2, p, dof, expected = chi2_contingency(contingency_table)

    print(f"\nüîπ {col} - p-valor: {p:.5f}")
    if p < 0.05:
        print("‚úÖ ‚Üí Relaci√≥n significativa con la readmisi√≥n")
    else:
        print("‚ùå ‚Üí No hay relaci√≥n significativa con la readmisi√≥n")

# Gr√°fico de barras de frecuencia de variables categ√≥ricas por readmisi√≥n
for col in categorical_cols:
    plt.figure(figsize=(10, 5))
    sns.countplot(data=data, x=col, hue=data['readmit_binary'].astype(str))
    plt.title(f"Distribuci√≥n de {col} por Readmisi√≥n")
    plt.xlabel(col)
    plt.ylabel("Frecuencia")
    plt.legend(title="Readmitido", labels=["No", "S√≠"])
    plt.xticks(rotation=45)
    plt.show()

"""Casi todas las variables categ√≥ricas tienen un impacto significativo en la readmisi√≥n, lo que indica que el historial cl√≠nico y el tratamiento del paciente pueden jugar un papel clave.

La variable medicaid no tiene un impacto estad√≠stico significativo, por lo que podr√≠amos descartarla en el modelo final.

# **Revisi√≥n del Enunciado y respuesta en nuestro an√°lisis**

1Ô∏è‚É£ <font color="red">Manejo de Valores Nulos</font> ‚úÖ <font color="green">RESUELTO</font>

1. Identificamos valores nulos: No hay valores nulos en el dataset.

2. M√©todo de imputaci√≥n: No fue necesario realizar imputaciones porque no hay valores nulos.

2Ô∏è‚É£ <font color="red">An√°lisis Univariante</font>

A) Variables Categ√≥ricas ‚úÖ <font color="green">RESUELTO</font>

Estudiamos cada variable categ√≥rica y mostramos su distribuci√≥n.

Convertimos las binarias a booleanas (diabetesMed, medicare, medicaid, had_emergency, had_inpatient_days, had_outpatient_days, readmit_binary).

Limpieza de valores: Se reemplazaron los espacios en los valores categ√≥ricos con _ para evitar problemas de procesamiento.

<font color="red">Respondimos las preguntas clave?:</font>

***¬øHay valores constantes o casi constantes?***

medicaid tiene una distribuci√≥n muy desigual y adem√°s no tiene una relaci√≥n significativa con la readmisi√≥n.

*¬øSe debe reducir el n√∫mero de categor√≠as de alguna variable?*

Variables como medical_specialty y primary_diagnosis podr√≠an agruparse m√°s en futuras etapas.

***¬øTienen sentido los datos observados?***

S√≠, los valores y distribuciones parecen l√≥gicos y consistentes con el problema.

B) Variables Num√©ricas ‚úÖ <font color="green">RESUELTO</font>

**An√°lisis de distribuci√≥n:**

Mostramos los boxplots e histogramas para observar la dispersi√≥n y outliers.

**Resumen estad√≠stico:**

Se analizaron media, mediana, percentiles y valores m√°ximos/m√≠nimos.

**Detecci√≥n de outliers:**

Algunos valores extremos, pero no eliminamos nada sin un criterio espec√≠fico.

3Ô∏è‚É£ <font color="red">An√°lisis Bivariante</font>

A) Correlaci√≥n entre Variables Num√©ricas ‚úÖ <font color="green">RESUELTO</font>

Calculamos la matriz de correlaci√≥n y la representamos con un heatmap.

<font color="red">Hallazgos:</font> No hay variables con correlaci√≥n >0.7, por lo que no eliminamos ninguna por multicolinealidad.

<font color="red">Sugerencia:</font> En futuras etapas, podr√≠amos aplicar PCA o feature selection para reducir la dimensionalidad.

B) Relaci√≥n entre Variables Num√©ricas y readmit_30_days ‚úÖ <font color="green">RESUELTO</font>

Se analizaron boxplots de cada variable num√©rica contra la readmisi√≥n.

C) Relaci√≥n entre Variables Categ√≥ricas y readmit_30_days ‚úÖ <font color="green">RESUELTO</font>

Realizamos el test de Chi-Cuadrado para todas las variables categ√≥ricas.

**Insights:**

Casi todas las variables categ√≥ricas tienen una relaci√≥n significativa con la readmisi√≥n.
medicaid fue la √∫nica sin relaci√≥n significativa, por lo que podemos eliminarla en la fase de modelado.
"""