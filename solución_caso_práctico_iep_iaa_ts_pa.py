# -*- coding: utf-8 -*-
"""Solución_Caso_Práctico_IEP_IAA_TS_pa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LnTix3pSq1cUMIDXhAIEeAvth9OwCfUl

# Preguntas Críticas Iniciales para Enfocar el Proyecto de Series Temporales (Gripe en Borgoña)

'''
Antes de implementar el proyecto en Google Colab, planteamos una serie de reflexiones clave que nos permitirán tomar decisiones fundamentadas en torno al análisis y modelado de la serie temporal:
'''

# 1. ¿Cómo es la estructura de la serie temporal?
- ¿Los datos están distribuidos de forma regular (semanalmente)?
- ¿Existen valores nulos, valores extremos o errores de entrada?
- ¿La serie está normalizada o requiere transformación?

# 2. ¿Existen patrones visibles de tendencia y estacionalidad?
- ¿Hay una tendencia creciente o decreciente en los casos de gripe?
- ¿Se observa estacionalidad anual (invierno/verano) o semanal?
- ¿Existe ruido blanco o ciclos repetitivos?

# 3. ¿La serie es estacionaria?
- Evaluar con visualización y pruebas como ADF (Augmented Dickey-Fuller).
- ¿Es necesario diferenciar la serie para estabilizar la varianza y la media?

# 4. ¿Qué preprocesamiento es necesario?
- ¿Requiere interpolación, suavizado, o eliminación de outliers?
- ¿Es necesario escalar los datos (ej. MinMaxScaler) para redes neuronales?

# 5. ¿Qué modelo de Machine Learning se adapta mejor a la serie?
- ¿Modelos como ARIMA, Prophet, o Random Forest pueden capturar la dinámica?
- ¿Podría usarse una regresión temporal o un modelo autoregresivo?

# 6. ¿Qué modelo de Deep Learning conviene?
- ¿Conviene usar una RNN, LSTM o GRU si hay secuencias largas?
- ¿Requiere ventanas deslizantes (time-delay embedding) como entrada?

# 7. ¿Cómo validaremos los modelos?
- ¿Usaremos un hold-out temporal (train/test split) o validación cruzada con ventana deslizante?
- Métricas: RMSE, MAE, MAPE para evaluar el rendimiento.

# 8. ¿Cómo reportaremos los resultados?
- Comparar rendimiento de modelos ML vs DL en una tabla.
- Mostrar predicciones y errores en gráficos (pred vs real).
"""

import pandas as pd
import matplotlib.pyplot as plt

# Cargar dataset
file_path = '/content/drive/MyDrive/Colab Notebooks/Proyecto_Aplicacion_TS/gripe.csv'
df = pd.read_csv(file_path)

# Renombrar columna si es necesario (para claridad)
df = df.rename(columns={'week': 'fecha', 'TauxGrippe': 'casos'})

# Convertir a datetime y ordenar cronológicamente
df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')
df = df.dropna(subset=['fecha'])
df = df.sort_values('fecha').set_index('fecha')

# Visualización inicial
plt.figure(figsize=(12, 5))
plt.plot(df['casos'], label='Casos de Gripe', color='darkcyan')
plt.title('📈 Evolución semanal de casos de gripe (Borgoña, 2004–2014)')
plt.xlabel('Fecha')
plt.ylabel('N° de casos')
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# Mostrar primeras filas para verificar
print("🔍 Primeras filas del dataset preparado:")
print(df.head())

from statsmodels.tsa.seasonal import seasonal_decompose

# Verificamos y eliminamos valores nulos
print(f" Valores nulos antes de limpiar: {df['casos'].isna().sum()}")
df_clean = df['casos'].dropna()
print(f" Valores nulos después de limpiar: {df_clean.isna().sum()}")

# Descomposición aditiva
result = seasonal_decompose(df_clean, model='additive', period=52)

# Visualizar componentes
plt.rcParams.update({'figure.figsize': (10, 8)})
result.plot()
plt.suptitle(' Descomposición de la serie temporal (modelo aditivo)', fontsize=14)
plt.tight_layout()
plt.show()

from statsmodels.tsa.stattools import adfuller

# Aplicar prueba de Dickey-Fuller a la serie limpia
adf_result = adfuller(df_clean)

print(" Prueba de Dickey-Fuller (ADF):")
print(f" Estadístico ADF: {adf_result[0]:.4f}")
print(f" p-valor: {adf_result[1]:.4f}")
print(" ¿La serie es estacionaria?:", " Sí" if adf_result[1] < 0.05 else "❌ No")

# Mostrar valores críticos
for key, value in adf_result[4].items():
    print(f"   ▪ Valor crítico ({key}): {value:.4f}")

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# ACF y PACF
fig, axes = plt.subplots(1, 2, figsize=(14, 4))
plot_acf(df_clean, lags=52, ax=axes[0])
plot_pacf(df_clean, lags=52, ax=axes[1])
axes[0].set_title(" ACF - Autocorrelación")
axes[1].set_title("⏸ PACF - Autocorrelación Parcial")
plt.tight_layout()
plt.show()

# Resetear índice temporal para extraer semana
df_seasonality = df_clean.reset_index()
df_seasonality['semana'] = df_seasonality['fecha'].dt.isocalendar().week
df_seasonality = df_seasonality[['semana', 'casos']]

# Calcular media por semana del año
weekly_avg = df_seasonality.groupby('semana')['casos'].mean()

# Visualización
plt.figure(figsize=(10, 4))
weekly_avg.plot()
plt.title(" Estacionalidad semanal promedio (2004–2014)")
plt.xlabel("Semana del año")
plt.ylabel("Casos promedio de gripe")
plt.grid(True)
plt.tight_layout()
plt.show()

"""# **Análisis Exploratorio y Diagnóstico de la Serie Temporal (Pasos 2 a 5)**

**Objetivo**

El objetivo de esta fase fue explorar en profundidad la estructura de la serie temporal de casos de gripe en Borgoña (2004–2014), descomponiéndola, evaluando su estacionariedad y detectando patrones de estacionalidad. Este análisis es fundamental para elegir el modelo más adecuado en fases posteriores.

1. Paso 2: Descomposición de la Serie Temporal

    Utilizamos un modelo aditivo para descomponer la serie casos en sus componentes:

    Tendencia: indica la evolución general del número de casos a lo largo del tiempo.

    Estacionalidad: revela patrones recurrentes semanales dentro del año.

    Ruido: la parte no explicada por la tendencia ni por la estacionalidad.

La visualización mostró una estacionalidad clara y recurrente, consistente con el comportamiento epidemiológico de la gripe, que tiende a aumentar en meses fríos.

2. Paso 3: Prueba de Estacionariedad (ADF)

  Aplicamos la prueba de Dickey-Fuller aumentada (ADF) para verificar si la serie es estacionaria.

  Un p-valor menor a 0.05 indica estacionariedad.

  En caso contrario, se requeriría diferenciación para usar ciertos modelos clásicos como ARIMA.

En este caso, la serie no resultó estacionaria, lo cual sugiere aplicar transformaciones o modelos robustos ante tendencias y estacionalidades.

3. Paso 4: Análisis ACF y PACF

Se graficaron las funciones:

    ACF (Autocorrelation Function): mide la correlación entre una observación y rezagos anteriores.

    PACF (Partial Autocorrelation Function): mide la correlación entre una observación y sus rezagos descontando efectos indirectos.

    Se observó una autocorrelación significativa hasta aproximadamente 10–12 semanas, reforzando la presencia de estructura temporal fuerte en los datos.

4. Paso 5: Estacionalidad Promedio Semanal

    Para confirmar la estacionalidad anual, agrupamos los datos por semana del año (del 1 al 52) y calculamos la media de casos por semana.

    El resultado mostró un claro pico estacional durante las semanas frías (invierno), con caídas sostenidas en primavera y verano. Esto justifica incorporar componentes estacionales o usar modelos con capacidad de capturar este tipo de variabilidad (p. ej., LSTM o modelos estacionales como SARIMA).

# **Conclusión Intermedia: Diagnóstico Final de la Serie**

Tras el análisis exploratorio y diagnóstico de la serie temporal, se han identificado varios aspectos clave que guían la siguiente etapa:

1. La serie no es estacionaria, por lo tanto, algunos modelos requerirán transformación previa (como diferenciación).

2. Existe estacionalidad anual clara, con picos concentrados en los meses de invierno.

3. Las gráficas ACF y PACF confirman la existencia de dependencias temporales que pueden ser aprovechadas por modelos secuenciales (p. ej., LSTM).

4. La distribución de los casos presenta alta variabilidad, lo que sugiere la conveniencia de escalar los datos antes de aplicar modelos neuronales.
"""

import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# 1️Estandarización/Normalización
scaler = MinMaxScaler()
df['casos_scaled'] = scaler.fit_transform(df[['casos']])

# 2️Generar ventanas deslizantes (lags) para aprendizaje supervisado
def create_supervised_dataset(series, n_lags=12):
    data = []
    target = []
    for i in range(n_lags, len(series)):
        data.append(series[i - n_lags:i])
        target.append(series[i])
    return np.array(data), np.array(target)

n_lags = 12  # número de semanas previas para predecir la siguiente
X, y = create_supervised_dataset(df['casos_scaled'].values, n_lags=n_lags)

# 3️Dividir entre entrenamiento y test (80%-20%), sin shuffle
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# 4️Para DL: añadir dimensión para redes LSTM/GRU [samples, time_steps, features]
X_train_dl = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_dl = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Confirmación de formas
print(f" ML - X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
print(f" DL - X_train_dl shape: {X_train_dl.shape}, y_train shape: {y_train.shape}")

"""# **Entrenamiento y evaluación del Modelo de Machine Learning**"""

# === PASOS 7–9: Preprocesamiento Final, Entrenamiento y Evaluación ===

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.optimizers import Adam

# --- Paso 7: Preprocesamiento ---

# Crear lags y target
final_lag = 12  # ventanas de 12 semanas (~3 meses)

def create_supervised_data(series, lags=12):
    df = pd.DataFrame()
    for i in range(1, lags + 1):
        df[f'lag_{i}'] = series.shift(i)
    df['target'] = series.values
    return df.dropna()

supervised_df = create_supervised_data(df['casos'], final_lag)

# Escalar los datos
scaler = MinMaxScaler()
supervised_scaled = pd.DataFrame(
    scaler.fit_transform(supervised_df),
    columns=supervised_df.columns,
    index=supervised_df.index
)

# Dividir en train/test
X = supervised_scaled.drop(columns=['target'])
y = supervised_scaled['target']
split_idx = int(len(X) * 0.8)
X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

# Preparar datos para modelo DL (LSTM espera 3D)
X_train_dl = np.expand_dims(X_train.values, axis=-1)
X_test_dl = np.expand_dims(X_test.values, axis=-1)

# --- Paso 8: Entrenamiento ML (Random Forest) ---
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# Evaluación ML
rf_mae = mean_absolute_error(y_test, rf_preds)
rf_rmse = mean_squared_error(y_test, rf_preds) ** 0.5
rf_r2 = r2_score(y_test, rf_preds)

print(" Rendimiento del modelo ML (Random Forest):")
print(f"MAE  : {rf_mae:.4f}")
print(f"RMSE : {rf_rmse:.4f}")
print(f"R²   : {rf_r2:.4f}")

# --- Paso 9: Entrenamiento DL (LSTM simple) ---
model_dl = Sequential()
model_dl.add(LSTM(50, activation='relu', input_shape=(X_train_dl.shape[1], 1)))
model_dl.add(Dense(1))
model_dl.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

model_dl.fit(X_train_dl, y_train, epochs=50, batch_size=16, verbose=0)
dl_preds = model_dl.predict(X_test_dl)

# Evaluación DL
_dl_preds = dl_preds.squeeze()
dl_mae = mean_absolute_error(y_test, _dl_preds)
dl_rmse = mean_squared_error(y_test, _dl_preds) ** 0.5
dl_r2 = r2_score(y_test, _dl_preds)

print("\n Rendimiento del modelo DL (LSTM):")
print(f"MAE  : {dl_mae:.4f}")
print(f"RMSE : {dl_rmse:.4f}")
print(f"R²   : {dl_r2:.4f}")

"""##  Comparación de Modelos: ML vs DL

###  Evaluación Final del Rendimiento

Tras aplicar técnicas de modelado tanto de Machine Learning (Random Forest) como de Deep Learning (LSTM), evaluamos ambos modelos usando métricas estándar de regresión: MAE (error absoluto medio), RMSE (raíz del error cuadrático medio) y R² (coeficiente de determinación).

| Modelo             | MAE    | RMSE   | R²     |
|--------------------|--------|--------|--------|
| Random Forest (ML) | 0.0335 | 0.0667 | 0.4720 |
| LSTM (DL)          | 0.0284 | 0.0616 | 0.5491 |

---

###  Interpretación de Resultados

- El modelo **LSTM** superó al modelo de **Random Forest** en las tres métricas de evaluación.
- La **mejora en R²** sugiere que LSTM captura mejor la dinámica secuencial y temporal de los datos.
- Dado que la serie temporal tiene cierto grado de estacionalidad y dependencia a largo plazo, el modelo LSTM —diseñado precisamente para este tipo de estructuras— ofrece una ventaja sustancial.

---

###  Conclusión

Ambos modelos ofrecen predicciones razonablemente buenas, pero el modelo **basado en Deep Learning (LSTM)** demuestra un mayor poder explicativo y menor error. Esto valida su idoneidad para tareas de forecasting en contextos temporales complejos como la evolución semanal de enfermedades.

 **Recomendación**: En escenarios futuros, podría explorarse el uso de arquitecturas más profundas (ej. BiLSTM, GRU), optimización de hiperparámetros, y técnicas de atención para capturar interacciones más complejas en series de salud pública.

## Reflexiones Críticas Iniciales del Proyecto

Antes de implementar cualquier modelo en este estudio de casos de gripe en la región de Borgoña (2004–2014), nos planteamos una serie de preguntas estratégicas para guiar nuestras decisiones analíticas y de modelado:

### 1. ¿Cómo es la estructura de la serie temporal?
- La serie está compuesta por observaciones **semanales**, lo cual es adecuado para modelado temporal.
- Detectamos y corregimos **valores nulos** para asegurar la consistencia analítica.
- Los valores originales (casos de gripe) fueron escalados entre 0 y 1 para la fase de Deep Learning, utilizando `MinMaxScaler`.

### 2. ¿Existen patrones de tendencia y estacionalidad?
- A través de la descomposición aditiva y análisis visual, **detectamos una clara estacionalidad anual**, con picos recurrentes en invierno.
- La tendencia es leve, con variaciones de fondo sin incremento lineal claro.
- Se identificó **ruido estructurado**, no completamente aleatorio, lo cual sugiere utilidad de modelos con memoria.

### 3. ¿La serie es estacionaria?
- Aplicamos la prueba **ADF (Dickey-Fuller Aumentada)**, y se concluyó que **la serie no es estacionaria** en su forma original.
- Se descartó la necesidad de diferenciación porque los modelos elegidos (Random Forest y LSTM) no exigen estacionariedad estricta.

### 4. ¿Qué preprocesamiento fue necesario?
- La serie fue **escalada** para el modelo LSTM y convertida en una estructura supervisada mediante lags temporales (`time-delay embedding`).
- Se generaron 12 lags (~3 meses) como ventana temporal de entrada.
- Se usaron técnicas de **train/test split** conservando la estructura temporal (sin mezclar en el tiempo).

### 5. ¿Qué modelo de Machine Learning aplicamos?
- Se utilizó **Random Forest Regressor**, un modelo robusto ante outliers y no linealidades.
- Resultó útil como línea base por su rapidez de entrenamiento y capacidad de captura de relaciones temporales en ventanas.

### 6. ¿Qué modelo de Deep Learning aplicamos?
- Se construyó un modelo **LSTM simple**, ideal para secuencias con dependencias temporales.
- Se alimentó con datos 3D `(samples, timesteps, features)` generados a partir de las ventanas temporales.

### 7. ¿Cómo se validaron los modelos?
- Se aplicó un esquema **hold-out temporal**, reservando el 20% final como conjunto de test.
- Se utilizaron las métricas **MAE, RMSE y R²** para una evaluación integral.

| Modelo        | MAE    | RMSE   | R²     |
|---------------|--------|--------|--------|
| Random Forest | 0.0335 | 0.0667 | 0.4720 |
| LSTM          | 0.0284 | 0.0616 | 0.5491 |

### 8. ¿Cómo se reportaron los resultados?
- Se construyó una **tabla comparativa**, resaltando el mejor modelo (LSTM).
- Se visualizó la serie temporal original, su estacionalidad, las autocorrelaciones y las predicciones.

---

**Conclusión final:** El modelo LSTM demostró un mejor ajuste y generalización frente a Random Forest, lo cual valida su aplicación en problemas de predicción de enfermedades estacionales. El pipeline implementado es replicable y escalable a otras regiones o enfermedades infecciosas.
"""