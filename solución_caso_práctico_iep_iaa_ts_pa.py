# -*- coding: utf-8 -*-
"""SoluciÃ³n_Caso_PrÃ¡ctico_IEP_IAA_TS_pa.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LnTix3pSq1cUMIDXhAIEeAvth9OwCfUl

# Preguntas CrÃ­ticas Iniciales para Enfocar el Proyecto de Series Temporales (Gripe en BorgoÃ±a)

'''
Antes de implementar el proyecto en Google Colab, planteamos una serie de reflexiones clave que nos permitirÃ¡n tomar decisiones fundamentadas en torno al anÃ¡lisis y modelado de la serie temporal:
'''

# 1. Â¿CÃ³mo es la estructura de la serie temporal?
- Â¿Los datos estÃ¡n distribuidos de forma regular (semanalmente)?
- Â¿Existen valores nulos, valores extremos o errores de entrada?
- Â¿La serie estÃ¡ normalizada o requiere transformaciÃ³n?

# 2. Â¿Existen patrones visibles de tendencia y estacionalidad?
- Â¿Hay una tendencia creciente o decreciente en los casos de gripe?
- Â¿Se observa estacionalidad anual (invierno/verano) o semanal?
- Â¿Existe ruido blanco o ciclos repetitivos?

# 3. Â¿La serie es estacionaria?
- Evaluar con visualizaciÃ³n y pruebas como ADF (Augmented Dickey-Fuller).
- Â¿Es necesario diferenciar la serie para estabilizar la varianza y la media?

# 4. Â¿QuÃ© preprocesamiento es necesario?
- Â¿Requiere interpolaciÃ³n, suavizado, o eliminaciÃ³n de outliers?
- Â¿Es necesario escalar los datos (ej. MinMaxScaler) para redes neuronales?

# 5. Â¿QuÃ© modelo de Machine Learning se adapta mejor a la serie?
- Â¿Modelos como ARIMA, Prophet, o Random Forest pueden capturar la dinÃ¡mica?
- Â¿PodrÃ­a usarse una regresiÃ³n temporal o un modelo autoregresivo?

# 6. Â¿QuÃ© modelo de Deep Learning conviene?
- Â¿Conviene usar una RNN, LSTM o GRU si hay secuencias largas?
- Â¿Requiere ventanas deslizantes (time-delay embedding) como entrada?

# 7. Â¿CÃ³mo validaremos los modelos?
- Â¿Usaremos un hold-out temporal (train/test split) o validaciÃ³n cruzada con ventana deslizante?
- MÃ©tricas: RMSE, MAE, MAPE para evaluar el rendimiento.

# 8. Â¿CÃ³mo reportaremos los resultados?
- Comparar rendimiento de modelos ML vs DL en una tabla.
- Mostrar predicciones y errores en grÃ¡ficos (pred vs real).
"""

import pandas as pd
import matplotlib.pyplot as plt

# Cargar dataset
file_path = '/content/drive/MyDrive/Colab Notebooks/Proyecto_Aplicacion_TS/gripe.csv'
df = pd.read_csv(file_path)

# Renombrar columna si es necesario (para claridad)
df = df.rename(columns={'week': 'fecha', 'TauxGrippe': 'casos'})

# Convertir a datetime y ordenar cronolÃ³gicamente
df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')
df = df.dropna(subset=['fecha'])
df = df.sort_values('fecha').set_index('fecha')

# VisualizaciÃ³n inicial
plt.figure(figsize=(12, 5))
plt.plot(df['casos'], label='Casos de Gripe', color='darkcyan')
plt.title('ğŸ“ˆ EvoluciÃ³n semanal de casos de gripe (BorgoÃ±a, 2004â€“2014)')
plt.xlabel('Fecha')
plt.ylabel('NÂ° de casos')
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# Mostrar primeras filas para verificar
print("ğŸ” Primeras filas del dataset preparado:")
print(df.head())

from statsmodels.tsa.seasonal import seasonal_decompose

# Verificamos y eliminamos valores nulos
print(f" Valores nulos antes de limpiar: {df['casos'].isna().sum()}")
df_clean = df['casos'].dropna()
print(f" Valores nulos despuÃ©s de limpiar: {df_clean.isna().sum()}")

# DescomposiciÃ³n aditiva
result = seasonal_decompose(df_clean, model='additive', period=52)

# Visualizar componentes
plt.rcParams.update({'figure.figsize': (10, 8)})
result.plot()
plt.suptitle(' DescomposiciÃ³n de la serie temporal (modelo aditivo)', fontsize=14)
plt.tight_layout()
plt.show()

from statsmodels.tsa.stattools import adfuller

# Aplicar prueba de Dickey-Fuller a la serie limpia
adf_result = adfuller(df_clean)

print(" Prueba de Dickey-Fuller (ADF):")
print(f" EstadÃ­stico ADF: {adf_result[0]:.4f}")
print(f" p-valor: {adf_result[1]:.4f}")
print(" Â¿La serie es estacionaria?:", " SÃ­" if adf_result[1] < 0.05 else "âŒ No")

# Mostrar valores crÃ­ticos
for key, value in adf_result[4].items():
    print(f"   â–ª Valor crÃ­tico ({key}): {value:.4f}")

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# ACF y PACF
fig, axes = plt.subplots(1, 2, figsize=(14, 4))
plot_acf(df_clean, lags=52, ax=axes[0])
plot_pacf(df_clean, lags=52, ax=axes[1])
axes[0].set_title(" ACF - AutocorrelaciÃ³n")
axes[1].set_title("â¸ PACF - AutocorrelaciÃ³n Parcial")
plt.tight_layout()
plt.show()

# Resetear Ã­ndice temporal para extraer semana
df_seasonality = df_clean.reset_index()
df_seasonality['semana'] = df_seasonality['fecha'].dt.isocalendar().week
df_seasonality = df_seasonality[['semana', 'casos']]

# Calcular media por semana del aÃ±o
weekly_avg = df_seasonality.groupby('semana')['casos'].mean()

# VisualizaciÃ³n
plt.figure(figsize=(10, 4))
weekly_avg.plot()
plt.title(" Estacionalidad semanal promedio (2004â€“2014)")
plt.xlabel("Semana del aÃ±o")
plt.ylabel("Casos promedio de gripe")
plt.grid(True)
plt.tight_layout()
plt.show()

"""# **AnÃ¡lisis Exploratorio y DiagnÃ³stico de la Serie Temporal (Pasos 2 a 5)**

**Objetivo**

El objetivo de esta fase fue explorar en profundidad la estructura de la serie temporal de casos de gripe en BorgoÃ±a (2004â€“2014), descomponiÃ©ndola, evaluando su estacionariedad y detectando patrones de estacionalidad. Este anÃ¡lisis es fundamental para elegir el modelo mÃ¡s adecuado en fases posteriores.

1. Paso 2: DescomposiciÃ³n de la Serie Temporal

    Utilizamos un modelo aditivo para descomponer la serie casos en sus componentes:

    Tendencia: indica la evoluciÃ³n general del nÃºmero de casos a lo largo del tiempo.

    Estacionalidad: revela patrones recurrentes semanales dentro del aÃ±o.

    Ruido: la parte no explicada por la tendencia ni por la estacionalidad.

La visualizaciÃ³n mostrÃ³ una estacionalidad clara y recurrente, consistente con el comportamiento epidemiolÃ³gico de la gripe, que tiende a aumentar en meses frÃ­os.

2. Paso 3: Prueba de Estacionariedad (ADF)

  Aplicamos la prueba de Dickey-Fuller aumentada (ADF) para verificar si la serie es estacionaria.

  Un p-valor menor a 0.05 indica estacionariedad.

  En caso contrario, se requerirÃ­a diferenciaciÃ³n para usar ciertos modelos clÃ¡sicos como ARIMA.

En este caso, la serie no resultÃ³ estacionaria, lo cual sugiere aplicar transformaciones o modelos robustos ante tendencias y estacionalidades.

3. Paso 4: AnÃ¡lisis ACF y PACF

Se graficaron las funciones:

    ACF (Autocorrelation Function): mide la correlaciÃ³n entre una observaciÃ³n y rezagos anteriores.

    PACF (Partial Autocorrelation Function): mide la correlaciÃ³n entre una observaciÃ³n y sus rezagos descontando efectos indirectos.

    Se observÃ³ una autocorrelaciÃ³n significativa hasta aproximadamente 10â€“12 semanas, reforzando la presencia de estructura temporal fuerte en los datos.

4. Paso 5: Estacionalidad Promedio Semanal

    Para confirmar la estacionalidad anual, agrupamos los datos por semana del aÃ±o (del 1 al 52) y calculamos la media de casos por semana.

    El resultado mostrÃ³ un claro pico estacional durante las semanas frÃ­as (invierno), con caÃ­das sostenidas en primavera y verano. Esto justifica incorporar componentes estacionales o usar modelos con capacidad de capturar este tipo de variabilidad (p. ej., LSTM o modelos estacionales como SARIMA).

# **ConclusiÃ³n Intermedia: DiagnÃ³stico Final de la Serie**

Tras el anÃ¡lisis exploratorio y diagnÃ³stico de la serie temporal, se han identificado varios aspectos clave que guÃ­an la siguiente etapa:

1. La serie no es estacionaria, por lo tanto, algunos modelos requerirÃ¡n transformaciÃ³n previa (como diferenciaciÃ³n).

2. Existe estacionalidad anual clara, con picos concentrados en los meses de invierno.

3. Las grÃ¡ficas ACF y PACF confirman la existencia de dependencias temporales que pueden ser aprovechadas por modelos secuenciales (p. ej., LSTM).

4. La distribuciÃ³n de los casos presenta alta variabilidad, lo que sugiere la conveniencia de escalar los datos antes de aplicar modelos neuronales.
"""

import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# 1ï¸EstandarizaciÃ³n/NormalizaciÃ³n
scaler = MinMaxScaler()
df['casos_scaled'] = scaler.fit_transform(df[['casos']])

# 2ï¸Generar ventanas deslizantes (lags) para aprendizaje supervisado
def create_supervised_dataset(series, n_lags=12):
    data = []
    target = []
    for i in range(n_lags, len(series)):
        data.append(series[i - n_lags:i])
        target.append(series[i])
    return np.array(data), np.array(target)

n_lags = 12  # nÃºmero de semanas previas para predecir la siguiente
X, y = create_supervised_dataset(df['casos_scaled'].values, n_lags=n_lags)

# 3ï¸Dividir entre entrenamiento y test (80%-20%), sin shuffle
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# 4ï¸Para DL: aÃ±adir dimensiÃ³n para redes LSTM/GRU [samples, time_steps, features]
X_train_dl = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_test_dl = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# ConfirmaciÃ³n de formas
print(f" ML - X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
print(f" DL - X_train_dl shape: {X_train_dl.shape}, y_train shape: {y_train.shape}")

"""# **Entrenamiento y evaluaciÃ³n del Modelo de Machine Learning**"""

# === PASOS 7â€“9: Preprocesamiento Final, Entrenamiento y EvaluaciÃ³n ===

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.optimizers import Adam

# --- Paso 7: Preprocesamiento ---

# Crear lags y target
final_lag = 12  # ventanas de 12 semanas (~3 meses)

def create_supervised_data(series, lags=12):
    df = pd.DataFrame()
    for i in range(1, lags + 1):
        df[f'lag_{i}'] = series.shift(i)
    df['target'] = series.values
    return df.dropna()

supervised_df = create_supervised_data(df['casos'], final_lag)

# Escalar los datos
scaler = MinMaxScaler()
supervised_scaled = pd.DataFrame(
    scaler.fit_transform(supervised_df),
    columns=supervised_df.columns,
    index=supervised_df.index
)

# Dividir en train/test
X = supervised_scaled.drop(columns=['target'])
y = supervised_scaled['target']
split_idx = int(len(X) * 0.8)
X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

# Preparar datos para modelo DL (LSTM espera 3D)
X_train_dl = np.expand_dims(X_train.values, axis=-1)
X_test_dl = np.expand_dims(X_test.values, axis=-1)

# --- Paso 8: Entrenamiento ML (Random Forest) ---
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# EvaluaciÃ³n ML
rf_mae = mean_absolute_error(y_test, rf_preds)
rf_rmse = mean_squared_error(y_test, rf_preds) ** 0.5
rf_r2 = r2_score(y_test, rf_preds)

print(" Rendimiento del modelo ML (Random Forest):")
print(f"MAE  : {rf_mae:.4f}")
print(f"RMSE : {rf_rmse:.4f}")
print(f"RÂ²   : {rf_r2:.4f}")

# --- Paso 9: Entrenamiento DL (LSTM simple) ---
model_dl = Sequential()
model_dl.add(LSTM(50, activation='relu', input_shape=(X_train_dl.shape[1], 1)))
model_dl.add(Dense(1))
model_dl.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

model_dl.fit(X_train_dl, y_train, epochs=50, batch_size=16, verbose=0)
dl_preds = model_dl.predict(X_test_dl)

# EvaluaciÃ³n DL
_dl_preds = dl_preds.squeeze()
dl_mae = mean_absolute_error(y_test, _dl_preds)
dl_rmse = mean_squared_error(y_test, _dl_preds) ** 0.5
dl_r2 = r2_score(y_test, _dl_preds)

print("\n Rendimiento del modelo DL (LSTM):")
print(f"MAE  : {dl_mae:.4f}")
print(f"RMSE : {dl_rmse:.4f}")
print(f"RÂ²   : {dl_r2:.4f}")

"""##  ComparaciÃ³n de Modelos: ML vs DL

###  EvaluaciÃ³n Final del Rendimiento

Tras aplicar tÃ©cnicas de modelado tanto de Machine Learning (Random Forest) como de Deep Learning (LSTM), evaluamos ambos modelos usando mÃ©tricas estÃ¡ndar de regresiÃ³n: MAE (error absoluto medio), RMSE (raÃ­z del error cuadrÃ¡tico medio) y RÂ² (coeficiente de determinaciÃ³n).

| Modelo             | MAE    | RMSE   | RÂ²     |
|--------------------|--------|--------|--------|
| Random Forest (ML) | 0.0335 | 0.0667 | 0.4720 |
| LSTM (DL)          | 0.0284 | 0.0616 | 0.5491 |

---

###  InterpretaciÃ³n de Resultados

- El modelo **LSTM** superÃ³ al modelo de **Random Forest** en las tres mÃ©tricas de evaluaciÃ³n.
- La **mejora en RÂ²** sugiere que LSTM captura mejor la dinÃ¡mica secuencial y temporal de los datos.
- Dado que la serie temporal tiene cierto grado de estacionalidad y dependencia a largo plazo, el modelo LSTM â€”diseÃ±ado precisamente para este tipo de estructurasâ€” ofrece una ventaja sustancial.

---

###  ConclusiÃ³n

Ambos modelos ofrecen predicciones razonablemente buenas, pero el modelo **basado en Deep Learning (LSTM)** demuestra un mayor poder explicativo y menor error. Esto valida su idoneidad para tareas de forecasting en contextos temporales complejos como la evoluciÃ³n semanal de enfermedades.

 **RecomendaciÃ³n**: En escenarios futuros, podrÃ­a explorarse el uso de arquitecturas mÃ¡s profundas (ej. BiLSTM, GRU), optimizaciÃ³n de hiperparÃ¡metros, y tÃ©cnicas de atenciÃ³n para capturar interacciones mÃ¡s complejas en series de salud pÃºblica.

## Reflexiones CrÃ­ticas Iniciales del Proyecto

Antes de implementar cualquier modelo en este estudio de casos de gripe en la regiÃ³n de BorgoÃ±a (2004â€“2014), nos planteamos una serie de preguntas estratÃ©gicas para guiar nuestras decisiones analÃ­ticas y de modelado:

### 1. Â¿CÃ³mo es la estructura de la serie temporal?
- La serie estÃ¡ compuesta por observaciones **semanales**, lo cual es adecuado para modelado temporal.
- Detectamos y corregimos **valores nulos** para asegurar la consistencia analÃ­tica.
- Los valores originales (casos de gripe) fueron escalados entre 0 y 1 para la fase de Deep Learning, utilizando `MinMaxScaler`.

### 2. Â¿Existen patrones de tendencia y estacionalidad?
- A travÃ©s de la descomposiciÃ³n aditiva y anÃ¡lisis visual, **detectamos una clara estacionalidad anual**, con picos recurrentes en invierno.
- La tendencia es leve, con variaciones de fondo sin incremento lineal claro.
- Se identificÃ³ **ruido estructurado**, no completamente aleatorio, lo cual sugiere utilidad de modelos con memoria.

### 3. Â¿La serie es estacionaria?
- Aplicamos la prueba **ADF (Dickey-Fuller Aumentada)**, y se concluyÃ³ que **la serie no es estacionaria** en su forma original.
- Se descartÃ³ la necesidad de diferenciaciÃ³n porque los modelos elegidos (Random Forest y LSTM) no exigen estacionariedad estricta.

### 4. Â¿QuÃ© preprocesamiento fue necesario?
- La serie fue **escalada** para el modelo LSTM y convertida en una estructura supervisada mediante lags temporales (`time-delay embedding`).
- Se generaron 12 lags (~3 meses) como ventana temporal de entrada.
- Se usaron tÃ©cnicas de **train/test split** conservando la estructura temporal (sin mezclar en el tiempo).

### 5. Â¿QuÃ© modelo de Machine Learning aplicamos?
- Se utilizÃ³ **Random Forest Regressor**, un modelo robusto ante outliers y no linealidades.
- ResultÃ³ Ãºtil como lÃ­nea base por su rapidez de entrenamiento y capacidad de captura de relaciones temporales en ventanas.

### 6. Â¿QuÃ© modelo de Deep Learning aplicamos?
- Se construyÃ³ un modelo **LSTM simple**, ideal para secuencias con dependencias temporales.
- Se alimentÃ³ con datos 3D `(samples, timesteps, features)` generados a partir de las ventanas temporales.

### 7. Â¿CÃ³mo se validaron los modelos?
- Se aplicÃ³ un esquema **hold-out temporal**, reservando el 20% final como conjunto de test.
- Se utilizaron las mÃ©tricas **MAE, RMSE y RÂ²** para una evaluaciÃ³n integral.

| Modelo        | MAE    | RMSE   | RÂ²     |
|---------------|--------|--------|--------|
| Random Forest | 0.0335 | 0.0667 | 0.4720 |
| LSTM          | 0.0284 | 0.0616 | 0.5491 |

### 8. Â¿CÃ³mo se reportaron los resultados?
- Se construyÃ³ una **tabla comparativa**, resaltando el mejor modelo (LSTM).
- Se visualizÃ³ la serie temporal original, su estacionalidad, las autocorrelaciones y las predicciones.

---

**ConclusiÃ³n final:** El modelo LSTM demostrÃ³ un mejor ajuste y generalizaciÃ³n frente a Random Forest, lo cual valida su aplicaciÃ³n en problemas de predicciÃ³n de enfermedades estacionales. El pipeline implementado es replicable y escalable a otras regiones o enfermedades infecciosas.
"""